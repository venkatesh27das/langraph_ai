# BI Chatbot POC

A proof-of-concept **agentic AI chatbot** for Business Intelligence that can answer queries from three knowledge sources: unstructured documents (RAG), structured data (SQL), and general knowledge (LLM). Built with **LangGraph** and **LM Studio**.

## ğŸš€ Quick Start

1. **Setup LM Studio**
   ```bash
   # Download and start LM Studio
   # Load a model (e.g., Llama 2 7B, Mistral 7B)
   # Start the local server on http://localhost:1234
   ```

2. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure**
   ```bash
   # Edit config.yaml with your settings
   cp config.yaml.example config.yaml
   ```

4. **Setup Data**
   ```bash
   python scripts/setup.py
   python scripts/generate_data_dict.py
   ```

5. **Run the App**
   ```bash
   streamlit run app.py
   ```

## ğŸ—ï¸ Architecture

```
User Query â†’ Intent Classification â†’ Route to Agent â†’ Generate Response
                    â†“
            [RAG | SQL | General | Clarification]
                    â†“
            Response + Visualizations (if applicable)
```

### Agents
- **RAG Agent**: Searches documents using vector similarity
- **SQL Agent**: Converts natural language to SQL queries
- **General Agent**: Uses LLM for general knowledge questions
- **Clarification Agent**: Handles vague queries and asks follow-ups

## ğŸ“ Project Structure

```
bi-chatbot-poc/
â”œâ”€â”€ app.py                          # Main Streamlit interface
â”œâ”€â”€ config.yaml                     # Configuration settings
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                     # LangGraph agents
â”‚   â”‚   â”œâ”€â”€ orchestrator.py         # Main workflow orchestrator
â”‚   â”‚   â”œâ”€â”€ rag_agent.py            # Document search & retrieval
â”‚   â”‚   â”œâ”€â”€ sql_agent.py            # SQL generation & execution
â”‚   â”‚   â”œâ”€â”€ general_agent.py        # General knowledge queries
â”‚   â”‚   â””â”€â”€ clarification_agent.py  # Query clarification
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                       # Core components
â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py         # Document processing & embeddings
â”‚   â”‚   â”œâ”€â”€ sql_generator.py        # Natural language to SQL
â”‚   â”‚   â”œâ”€â”€ data_dictionary.py      # Auto-generated schema info
â”‚   â”‚   â”œâ”€â”€ lm_studio_client.py     # LM Studio API client
â”‚   â”‚   â”œâ”€â”€ chart_generator.py      # Data visualization
â”‚   â”‚   â””â”€â”€ conversation_memory.py  # Multi-turn conversations
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts.py                  # LLM prompt templates
â”‚   â””â”€â”€ utils.py                    # Helper functions
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/                  # PDF, TXT, MD files
â”‚   â”œâ”€â”€ sample_db.sqlite           # Sample database
â”‚   â””â”€â”€ embeddings/                # Vector store
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.py                   # Initial setup
â”‚   â””â”€â”€ generate_data_dict.py      # Auto data dictionary
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ experimentation.ipynb      # Testing & exploration
```

## ğŸ”§ Configuration

Edit `config.yaml`:

```yaml
lm_studio:
  base_url: "http://localhost:1234/v1"
  model: "local-model"

database:
  path: "data/sample_db.sqlite"
  
rag:
  documents_path: "data/documents"
  embeddings_path: "data/embeddings"
  chunk_size: 1000
```

## ğŸ’¡ Example Queries

### ğŸ“„ Document Questions (RAG)
- "What does our employee handbook say about vacation policies?"
- "Show me the Q3 performance highlights"
- "What are the key findings from the market research?"

### ğŸ“Š Data Questions (SQL)
- "What were our total sales last month?"
- "Show me the top 5 customers by revenue"
- "How many new customers did we acquire this quarter?"

### â“ General Questions
- "What is business intelligence?"
- "Explain KPIs vs metrics"
- "Best practices for data visualization"

## ğŸ¯ Key Features

- **Multi-source Intelligence**: RAG + SQL + General Knowledge
- **Agentic Architecture**: LangGraph-powered workflow
- **Local LLM**: Privacy-first with LM Studio
- **Smart Routing**: Automatic intent classification
- **Clarification Handling**: Asks follow-ups for vague queries
- **Multi-turn Conversations**: Maintains context across exchanges
- **Auto Data Dictionary**: LLM-generated schema documentation
- **Visual Insights**: Automatic chart generation from SQL results
- **Interactive UI**: Streamlit-based chat interface

## ğŸ”„ Workflow

1. **User Input** â†’ Intent classification
2. **Route to Agent** based on query type
3. **Process Query**:
   - RAG: Retrieve relevant documents â†’ Generate answer
   - SQL: Generate SQL â†’ Execute â†’ Create insights + charts
   - General: Direct LLM response
   - Clarification: Ask follow-up questions
4. **Return Response** with context and visualizations

## ğŸ› ï¸ Setup Details

### Data Dictionary Generation
```bash
python scripts/generate_data_dict.py
# Automatically analyzes your database schema
# Generates descriptions and relationships using LLM
```

### Adding Documents
```bash
# Place PDF, TXT, or MD files in data/documents/
# Run setup to process and embed documents
python scripts/setup.py --rebuild-embeddings
```

### Custom Database
```bash
# Replace data/sample_db.sqlite with your database
# Update config.yaml with the new path
# Regenerate data dictionary
```

## ğŸš¨ Limitations (POC)

- Single SQLite database support
- Basic error handling
- Limited visualization types
- No user authentication
- Local deployment only
- Simplified intent classification

## ğŸ“‹ Requirements

- Python 3.8+
- LM Studio with local model
- 4GB+ RAM for embeddings
- SQLite database

## ğŸ¤ Contributing

This is a proof-of-concept. Feel free to:
- Test different LLM models
- Add new data sources
- Improve visualization types
- Enhance error handling
- Experiment with prompt engineering

## ğŸ“„ License

MIT License - See LICENSE file for details